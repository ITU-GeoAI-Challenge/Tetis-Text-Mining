{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c78d6df7",
   "metadata": {},
   "source": [
    "[![tetis](https://www.umr-tetis.fr/images/logo-header-tetis.png)](https://www.umr-tetis.fr/index.php)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2414de92",
   "metadata": {},
   "source": [
    "# 1. Prepare the model\n",
    "## 1.1 Load the model from huggingFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a65d24b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"rdecoupes/tetis-geochallenge\")\n",
    "\n",
    "model = AutoModelForTokenClassification.from_pretrained(\"rdecoupes/tetis-geochallenge\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac6fa79c",
   "metadata": {},
   "source": [
    "## 1.2 Create the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fa01dc87",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# transforms bilou format into IOB in order to do an aggregation\n",
    "nlp = pipeline(\"ner\", model=model, tokenizer=tokenizer, aggregation_strategy=\"simple\")\n",
    "nlp.model.config.id2label = {k: v.replace('L-', 'I-').replace('U-', 'B-') for k, v in nlp.model.config.id2label.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b10977",
   "metadata": {},
   "source": [
    "## 1.3 Define post-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa54af72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(tweet_text):\n",
    "    # remove hashtag\n",
    "    if tweet_text[0] == \"#\": # if it's at the beginning of the sentence, we remove # by \",\" because otherwise tokenizer remove a character\n",
    "        tweet_text = \"'\" + tweet_text[1:]\n",
    "        pass\n",
    "    # else:\n",
    "    #     tweet_text = tweet_text.replace(\"#\", \" \")\n",
    "    tweet_text = tweet_text.replace(\"#\", \" \")\n",
    "    return tweet_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "278eb74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nlp_results_to_location_mentions(entities):\n",
    "    list_location_mentions = []\n",
    "    # trouble with pipeline tokenizer that can't aggregate successfully the subtokens\n",
    "    for_restart = True\n",
    "    while(for_restart):\n",
    "        for_restart = False\n",
    "        if len(entities) > 1:\n",
    "            for i, ent in enumerate(entities):\n",
    "                try:\n",
    "                    if entities[i][\"end\"] == entities[i+1][\"start\"]:# they are subtokens\n",
    "                        entities[i][\"word\"] = entities[i][\"word\"] + entities[i+1][\"word\"]\n",
    "                        entities[i][\"end\"] = entities[i+1][\"end\"]\n",
    "                        entities.remove(entities[i+1])\n",
    "                        for_restart = True\n",
    "                        break\n",
    "                except:\n",
    "                    continue\n",
    "\n",
    "    for ent in entities:\n",
    "        # trouble with pipeline tokenizer: it often puts a white space at the beginning of the token\n",
    "        if ent[\"word\"].startswith(\" \"):\n",
    "            ent[\"word\"] = ent[\"word\"][1:]\n",
    "        if ent[\"word\"].startswith(\"#\"): # we remove '#' if any\n",
    "            ent[\"word\"] = ent[\"word\"][1:]\n",
    "            ent[\"start\"] = ent[\"start\"] + 1\n",
    "        if ent[\"word\"].startswith(\"'\"): # we remove ''' if any (comes from the preprocessing when the sentences starts by a keyword)\n",
    "            ent[\"word\"] = ent[\"word\"][1:]\n",
    "            ent[\"start\"] = ent[\"start\"] + 1\n",
    "        location_mention = {\n",
    "            \"text\": ent[\"word\"],\n",
    "            \"start_offset\": ent[\"start\"],\n",
    "            \"end_offset\": ent[\"end\"]\n",
    "        }\n",
    "        list_location_mentions.append(location_mention)\n",
    "    return list_location_mentions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffbe7f23",
   "metadata": {},
   "source": [
    "# 2. Use the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4c5b6931",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "example_list = [\n",
    "    \"My name is Sarah and I live in London\",\n",
    "    \"My name is Wolfgang and I live in Berlin\",\n",
    "    \"My name is Clara and I live in Berkeley, California.\"\n",
    "]\n",
    "\n",
    "df = pd.DataFrame(example_list, columns=[\"text\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "260a366e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>My name is Sarah and I live in London</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>My name is Wolfgang and I live in Berlin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>My name is Clara and I live in Berkeley, Calif...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0              My name is Sarah and I live in London\n",
       "1           My name is Wolfgang and I live in Berlin\n",
       "2  My name is Clara and I live in Berkeley, Calif..."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9762a0bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"text\"] = df[\"text\"].apply(preprocessing)\n",
    "df[\"predicted\"] = df[\"text\"].apply(nlp)\n",
    "df[\"location_mentions\"] = df[\"predicted\"].apply(nlp_results_to_location_mentions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7ba56cab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>predicted</th>\n",
       "      <th>location_mentions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>My name is Sarah and I live in London</td>\n",
       "      <td>[{'entity_group': 'LOC', 'score': 0.9956161, '...</td>\n",
       "      <td>[{'text': 'London', 'start_offset': 31, 'end_o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>My name is Wolfgang and I live in Berlin</td>\n",
       "      <td>[{'entity_group': 'LOC', 'score': 0.9885152, '...</td>\n",
       "      <td>[{'text': 'Berlin', 'start_offset': 34, 'end_o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>My name is Clara and I live in Berkeley, Calif...</td>\n",
       "      <td>[{'entity_group': 'LOC', 'score': 0.93376523, ...</td>\n",
       "      <td>[{'text': 'Berkeley', 'start_offset': 31, 'end...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0              My name is Sarah and I live in London   \n",
       "1           My name is Wolfgang and I live in Berlin   \n",
       "2  My name is Clara and I live in Berkeley, Calif...   \n",
       "\n",
       "                                           predicted  \\\n",
       "0  [{'entity_group': 'LOC', 'score': 0.9956161, '...   \n",
       "1  [{'entity_group': 'LOC', 'score': 0.9885152, '...   \n",
       "2  [{'entity_group': 'LOC', 'score': 0.93376523, ...   \n",
       "\n",
       "                                   location_mentions  \n",
       "0  [{'text': 'London', 'start_offset': 31, 'end_o...  \n",
       "1  [{'text': 'Berlin', 'start_offset': 34, 'end_o...  \n",
       "2  [{'text': 'Berkeley', 'start_offset': 31, 'end...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e31ee922",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
